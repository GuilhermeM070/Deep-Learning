{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1962,
     "status": "ok",
     "timestamp": 1574788685363,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCfgXxjTVPyGE0vH1sGz0gI39poyLbeKld6jeGHhEg=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "Jo3G-RN7t2kl",
    "outputId": "f87b3470-0974-48c5-cc92-cbea2277d1df"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tns \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m      3\u001b[0m tns1 \u001b[38;5;241m=\u001b[39m tns[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tns = torch.randn(9, 12)\n",
    "tns1 = tns[0:5, 0:4]\n",
    "tns2 = tns[5:, 4:]\n",
    "\n",
    "resultado = torch.mm(tns1, tns2)\n",
    "print(resultado.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c25hqijfflPT"
   },
   "source": [
    "# Sintaxe básica do Pytorch\n",
    "\n",
    "Assim como o NumPy, o Pytorch é uma biblioteca de processamento vetorial/matricial/tensorial. Operações sobre os tensores do Pytorch possuem sintaxe consideravelmente parecida com operações sobre tensores do NumPy.\n",
    "\n",
    "Para mais informações sobre tensores em PyTorch, consulte a documentação: <br> https://pytorch.org/docs/stable/tensors.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pIHvu_8afoi2"
   },
   "source": [
    "## Tipos de tensores \n",
    "\n",
    "Você pode criar tensores do PyTorch de inúmeras formas! Vamos ver primeiro os tipos de tensores que estão ao nosso dispor. Para isso, vamos converter listas comuns do Python em tensors do PyTorch.\n",
    "\n",
    "Note que a impressão de tensores dos tipos ```float32``` e ```int64``` não vêm acompanhadas do parâmetro de tipo ```dtype```, visto que se tratam dos tipos padrão trabalhados pelo PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnOEg66FjD2F"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m lista \u001b[38;5;241m=\u001b[39m [ [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m      3\u001b[0m           [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m] ]\n\u001b[0;32m      5\u001b[0m tns \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(lista)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "lista = [ [1,2,3],\n",
    "          [4,5,6] ]\n",
    "\n",
    "tns = torch.Tensor(lista)\n",
    "print(tns.dtype)\n",
    "print(tns)\n",
    "\n",
    "print('')\n",
    "tns = torch.DoubleTensor(lista)\n",
    "print(tns.dtype)\n",
    "print(tns)\n",
    "\n",
    "print('')\n",
    "tns = torch.LongTensor(lista)\n",
    "print(tns.dtype)\n",
    "print(tns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gxA-fH8bq_fQ"
   },
   "source": [
    "## Outras formas de instanciar tensores\n",
    "\n",
    "### A partir de arrays Numpy\n",
    "$torch.from\\_numpy()$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNxZ-rMHq-xd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "int32\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m tns \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(arr)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(tns)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(tns\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.random.rand(3,4)\n",
    "arr = arr.astype(int)\n",
    "print(arr)\n",
    "print(arr.dtype)\n",
    "\n",
    "print('')\n",
    "tns = torch.from_numpy(arr)\n",
    "print(tns)\n",
    "print(tns.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7QC4F0AqkpPb"
   },
   "source": [
    "### Tensores inicializados\n",
    "Essas funções recebem como parâmetro o tamanho de cada dimensão do tensor. Aqui vamos conhecer as seguintes funções:\n",
    "\n",
    "$torch.ones()$ -> Cria um tensor preenchido com zeros.\n",
    "\n",
    "$torch.zeros()$ -> Cria um tensor preenchido com uns.\n",
    "\n",
    "$torch.randn()$ -> Cria um tensor preenchido com números aleatórios a partir de uma distribuição normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZ0kLNgtko5O"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tns1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[0;32m      2\u001b[0m tns0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m tnsr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "tns1 = torch.ones(2, 3)\n",
    "tns0 = torch.zeros(3, 5)\n",
    "tnsr = torch.randn(3, 3)\n",
    "\n",
    "print(tns1)\n",
    "print(tns0)\n",
    "print(tnsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lf9piGFVnx6m"
   },
   "source": [
    "### Tensor para array numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FLGt-iw2n3Za"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tnsr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m arr \u001b[39m=\u001b[39m tnsr\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(arr)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tnsr' is not defined"
     ]
    }
   ],
   "source": [
    "arr = tnsr.data.numpy()\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X07bm9KBnMtA"
   },
   "source": [
    "## Indexação\n",
    "\n",
    "De posse dessa informação, a indexação é feita de forma similar a arrays Numpy, através da sintaxe de colchetes ```[]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8jRdxHTpCN0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tnsr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# tnsr[0,1]\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(tnsr[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(tnsr[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tnsr' is not defined"
     ]
    }
   ],
   "source": [
    "# tnsr[0,1]\n",
    "\n",
    "print(tnsr[0:2, 2].data.numpy())\n",
    "print(tnsr[0, 1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzGW3gVTqK4y"
   },
   "source": [
    "## Operações com tensores\n",
    "\n",
    "A função ```.item()``` utilizada anteriormente extrai o número de um tensor que possui um único valor, permitindo realizar as operações numéricas do Python. Caso o item não seja extraído, operações que envolvam tensores vão retornar novos tensores.\n",
    "\n",
    "Vale ressaltar também que operações entre tensores são realizadas **ponto a ponto**, operando cada elemento ```(i, j)``` do tensor ```t1```, com o elemento ```(i, j)``` do tensor ```t2```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuQTTUf6QiY0"
   },
   "outputs": [],
   "source": [
    "tns1 = torch.randn(2,2,3)\n",
    "tns2 = torch.ones(2,2,3)\n",
    "\n",
    "print(tns1)\n",
    "print(tns2)\n",
    "\n",
    "print('')\n",
    "\n",
    "print(tns1*tns2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-N_PETWtMZ7"
   },
   "source": [
    "## Função ```.size()``` e ```.view()```\n",
    "\n",
    "Uma operações **importantíssima** na manipulação de tensores para Deep Learning é a reorganização das suas dimensões. Dessa forma podemos, por exemplo, **linearizar um tensor n-dimensional**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKgCe5brte2L"
   },
   "outputs": [],
   "source": [
    "print(tns2.size())\n",
    "\n",
    "print(tns2.view(tns2.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0o4_LzQoz0Ti"
   },
   "source": [
    "## GPU Cast\n",
    "\n",
    "Para que o seu script dê suporte a infraestruturas com e sem GPU, é importante definir o dispositivo no início do seu código de acordo com a verificação apresentada a seguir. Essa definição de dispositivo será utilizada toda vez que precisarmos subir valores na GPU, como os pesos da rede, os gradientes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6690,
     "status": "ok",
     "timestamp": 1571694690168,
     "user": {
      "displayName": "Camila Laranjeira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCfgXxjTVPyGE0vH1sGz0gI39poyLbeKld6jeGHhEg=s64",
      "userId": "03895474106233302954"
     },
     "user_tz": 180
    },
    "id": "uePyYun4z1u3",
    "outputId": "2e6b9822-54ed-4c91-ce1a-cfa1f81a4ccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  \n",
    "print(device)\n",
    "tns2 = tns2.to(device)\n",
    "print(tns2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sintaxe do Pytorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
